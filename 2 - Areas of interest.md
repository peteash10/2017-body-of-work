#Areas of Interest

Enquiry into the production and consumption of images in the 21st century is a dauntingly huge challenge. My process over the next few months will be to narrow my areas of interest to a manageable number of subjects suitable for the production of new work. Here is the current list. 

##Neural Networks

[Deep Dream](http://deepdreamgenerator.com), [Style Transfer](https://frankzliu.com/artistic-style-transfer/), etc. 


Images have been used as a diagnostic tool to understand how [convoluted neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) (complex algorithms which "learn") work, and in turn have images which provoke our understanding of creativity. 

Interesting to me because it is a non-visual way of understanding, and producing, visual images and has implications for computer vision. 

###t-SNE Sorting

Related to neural networks (I think) t-SNE is a methodology for sorting images based on their contents. It's an interesting approach to dealing with thousands of images and something I want to explore. 

[Gene Kogan is doing work in this area](https://github.com/genekogan/ofxTSNE).



##Photogrammetry

[Photogrammetry](https://en.wikipedia.org/wiki/Photogrammetry) is the process by which multiple photographs (or video frames) of the same object from different angles can be translated into a 3D rendering of that object. [Originally used](https://github.com/golanlevin/ExperimentalCapture/blob/master/docs/Photogrammetry-and-3D-scanning.md) to determine topographical heights from aerial photography this is now a common form of 3D scanning. The process involves identifting similar points in photos and calcuating their position in 3D space. 

Interesting to me because photos as data and the translation from 2D to 3D. Also very glitchy.

##Depth Capture

[LiDAR](https://en.wikipedia.org/wiki/Lidar) and [Kinect](https://en.wikipedia.org/wiki/Kinect). They're cameras, but they're not cameras. Adding a new dimension of depth. See also [DepthKit](http://www.depthkit.tv) and work with the [LiDAR unit I recently bought](https://github.com/golanlevin/ExperimentalCapture/tree/master/students/benjamin/project3)

Interesting to me because they push the edges of "what is a camera" in a relatively comprehendable way, plus they really do just produce data which has to be rendered in an arbitrary way to be understood. 

Particularly want to rethink how they "see". 

##Mutispectral Imaging

Moving out of the visual RGB band and looking at non-visible light and radio waves.

* Near Infra Red
* Ultra Violet
* Infra Red
* etc

[Good overview from Golan Levin.](https://github.com/golanlevin/ExperimentalCapture/blob/master/docs/hyperspectral.md)

Interesting because computers can capture the spectrums that we can't see.

##There Is Only Software

To quote Lev Manovich:

> Depending on the software I am using, the “properties” of a media object can change dramatically. Exactly the same file with the same contents can take on a variety of identities depending on the software being used. What does this finding means in relation to the persisting primacy of the term “digital” in understanding new media? Let me answer this as clear and direct as I can. There is no such thing as “digital media.” There is only software – as applied to media data (or “content”).





